/tmp/slurmd/job1384007/slurm_script: line 9: cd: qb18517/11_DT/dynamicTextureMain/4_C3D_ConvolutionalNN_3D/: No such file or directory
cuda:0
No handlers could be found for logger "libav.swscaler"
No handlers could be found for logger "libav.swscaler"
No handlers could be found for logger "libav.swscaler"
No handlers could be found for logger "libav.swscaler"
No handlers could be found for logger "libav.swscaler"
No handlers could be found for logger "libav.swscaler"
2_C3D_Model_BC.py:93: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
2_C3D_Model_BC.py:135: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  print(epoch,i,loss.data[0])#, loss.data[0])
(0, 1, tensor(3.8764, device='cuda:0'))
(0, 2, tensor(3.8365, device='cuda:0'))
(0, 3, tensor(3.8272, device='cuda:0'))
(0, 4, tensor(3.8120, device='cuda:0'))
(0, 5, tensor(3.8272, device='cuda:0'))
No handlers could be found for logger "libav.swscaler"
(0, 6, tensor(3.7776, device='cuda:0'))
(0, 7, tensor(3.7682, device='cuda:0'))
(0, 8, tensor(3.8509, device='cuda:0'))
(0, 9, tensor(3.7929, device='cuda:0'))
(0, 10, tensor(3.7878, device='cuda:0'))
No handlers could be found for logger "libav.swscaler"
(0, 11, tensor(3.8462, device='cuda:0'))
(0, 12, tensor(3.7700, device='cuda:0'))
(0, 13, tensor(3.8210, device='cuda:0'))
(0, 14, tensor(3.7687, device='cuda:0'))
(0, 15, tensor(3.7092, device='cuda:0'))
(0, 16, tensor(3.7412, device='cuda:0'))
(0, 17, tensor(3.6996, device='cuda:0'))
(0, 18, tensor(3.7675, device='cuda:0'))
(0, 19, tensor(3.7761, device='cuda:0'))
(0, 20, tensor(3.7128, device='cuda:0'))
(0, 21, tensor(3.7297, device='cuda:0'))
(0, 22, tensor(3.6130, device='cuda:0'))
(0, 23, tensor(3.9171, device='cuda:0'))
(0, 24, tensor(3.8066, device='cuda:0'))
(0, 25, tensor(3.8530, device='cuda:0'))
(0, 26, tensor(3.8046, device='cuda:0'))
(0, 27, tensor(3.7763, device='cuda:0'))
(0, 28, tensor(3.7438, device='cuda:0'))
(0, 29, tensor(3.8067, device='cuda:0'))
(0, 30, tensor(3.6518, device='cuda:0'))
(0, 31, tensor(3.6621, device='cuda:0'))
(0, 32, tensor(3.6626, device='cuda:0'))
(0, 33, tensor(3.9680, device='cuda:0'))
(0, 34, tensor(3.6899, device='cuda:0'))
(0, 35, tensor(3.7901, device='cuda:0'))
(0, 36, tensor(3.6817, device='cuda:0'))
(0, 37, tensor(3.8680, device='cuda:0'))
(0, 38, tensor(3.7349, device='cuda:0'))
(0, 39, tensor(3.6557, device='cuda:0'))
(0, 40, tensor(3.6615, device='cuda:0'))
(0, 41, tensor(3.8454, device='cuda:0'))
(0, 42, tensor(3.7475, device='cuda:0'))
(0, 43, tensor(3.6823, device='cuda:0'))
(0, 44, tensor(3.6619, device='cuda:0'))
(0, 45, tensor(3.8110, device='cuda:0'))
(0, 46, tensor(3.7980, device='cuda:0'))
(0, 47, tensor(3.7003, device='cuda:0'))
(0, 48, tensor(3.7090, device='cuda:0'))
(0, 49, tensor(3.8073, device='cuda:0'))
(0, 50, tensor(3.7498, device='cuda:0'))
(0, 51, tensor(3.7171, device='cuda:0'))
(0, 52, tensor(3.7981, device='cuda:0'))
(0, 53, tensor(3.8079, device='cuda:0'))
(0, 54, tensor(3.7171, device='cuda:0'))
(0, 55, tensor(3.7492, device='cuda:0'))
(0, 56, tensor(3.7664, device='cuda:0'))
(0, 57, tensor(3.7824, device='cuda:0'))
(0, 58, tensor(3.7471, device='cuda:0'))
(0, 59, tensor(3.6304, device='cuda:0'))
(0, 60, tensor(3.6525, device='cuda:0'))
(0, 61, tensor(3.7450, device='cuda:0'))
(0, 62, tensor(3.5892, device='cuda:0'))
(0, 63, tensor(3.5982, device='cuda:0'))
(0, 64, tensor(3.4552, device='cuda:0'))
(0, 65, tensor(3.6640, device='cuda:0'))
(0, 66, tensor(3.6143, device='cuda:0'))
(0, 67, tensor(3.7959, device='cuda:0'))
(0, 68, tensor(3.7210, device='cuda:0'))
(0, 69, tensor(3.5960, device='cuda:0'))
(0, 70, tensor(3.5465, device='cuda:0'))
(0, 71, tensor(3.7099, device='cuda:0'))
(0, 72, tensor(3.8198, device='cuda:0'))
(0, 73, tensor(3.7697, device='cuda:0'))
(0, 74, tensor(3.6075, device='cuda:0'))
(0, 75, tensor(3.7222, device='cuda:0'))
(0, 76, tensor(3.5803, device='cuda:0'))
(0, 77, tensor(3.7764, device='cuda:0'))
(0, 78, tensor(3.7851, device='cuda:0'))
(0, 79, tensor(3.7223, device='cuda:0'))
(0, 80, tensor(3.6246, device='cuda:0'))
(0, 81, tensor(3.7107, device='cuda:0'))
(0, 82, tensor(3.5527, device='cuda:0'))
(0, 83, tensor(3.7325, device='cuda:0'))
(0, 84, tensor(3.7817, device='cuda:0'))
(0, 85, tensor(3.6736, device='cuda:0'))
(0, 86, tensor(3.7007, device='cuda:0'))
(0, 87, tensor(3.6031, device='cuda:0'))
(0, 88, tensor(3.6271, device='cuda:0'))
(0, 89, tensor(3.6344, device='cuda:0'))
(0, 90, tensor(3.7121, device='cuda:0'))
(0, 91, tensor(3.6064, device='cuda:0'))
(0, 92, tensor(3.8117, device='cuda:0'))
(0, 93, tensor(3.8088, device='cuda:0'))
(0, 94, tensor(3.6401, device='cuda:0'))
(0, 95, tensor(3.7154, device='cuda:0'))
(0, 96, tensor(3.7019, device='cuda:0'))
(0, 97, tensor(3.7367, device='cuda:0'))
(0, 98, tensor(3.6136, device='cuda:0'))
(0, 99, tensor(3.6397, device='cuda:0'))
(0, 100, tensor(3.8462, device='cuda:0'))
(0, 101, tensor(3.7638, device='cuda:0'))
(0, 102, tensor(3.6809, device='cuda:0'))
(0, 103, tensor(3.5694, device='cuda:0'))
(0, 104, tensor(3.5195, device='cuda:0'))
(0, 105, tensor(3.5482, device='cuda:0'))
(0, 106, tensor(3.9509, device='cuda:0'))
(0, 107, tensor(3.7958, device='cuda:0'))
(0, 108, tensor(3.6746, device='cuda:0'))
(0, 109, tensor(3.6729, device='cuda:0'))
(0, 110, tensor(3.5902, device='cuda:0'))
(0, 111, tensor(3.7030, device='cuda:0'))
(0, 112, tensor(3.7623, device='cuda:0'))
(0, 113, tensor(3.6599, device='cuda:0'))
(0, 114, tensor(3.7158, device='cuda:0'))
(0, 115, tensor(3.6562, device='cuda:0'))
(0, 116, tensor(3.6289, device='cuda:0'))
(0, 117, tensor(3.7405, device='cuda:0'))
(0, 118, tensor(3.7021, device='cuda:0'))
(0, 119, tensor(3.5898, device='cuda:0'))
(0, 120, tensor(3.7169, device='cuda:0'))
(0, 121, tensor(3.3973, device='cuda:0'))
(0, 122, tensor(3.5855, device='cuda:0'))
(0, 123, tensor(3.5843, device='cuda:0'))
(0, 124, tensor(3.6138, device='cuda:0'))
(0, 125, tensor(3.4580, device='cuda:0'))
(0, 126, tensor(3.7865, device='cuda:0'))
(0, 127, tensor(3.7841, device='cuda:0'))
(0, 128, tensor(3.7023, device='cuda:0'))
(0, 129, tensor(3.7616, device='cuda:0'))
(0, 130, tensor(3.5230, device='cuda:0'))
(0, 131, tensor(3.5833, device='cuda:0'))
(0, 132, tensor(3.5620, device='cuda:0'))
(0, 133, tensor(3.6185, device='cuda:0'))
(0, 134, tensor(3.8204, device='cuda:0'))
(0, 135, tensor(3.7127, device='cuda:0'))
(0, 136, tensor(3.5216, device='cuda:0'))
(0, 137, tensor(3.7194, device='cuda:0'))
(0, 138, tensor(3.7733, device='cuda:0'))
(0, 139, tensor(3.6965, device='cuda:0'))
(0, 140, tensor(3.5728, device='cuda:0'))
(0, 141, tensor(3.7374, device='cuda:0'))
(0, 142, tensor(3.6804, device='cuda:0'))
(0, 143, tensor(3.5132, device='cuda:0'))
(0, 144, tensor(3.6404, device='cuda:0'))
(0, 145, tensor(3.7625, device='cuda:0'))
(0, 146, tensor(3.6911, device='cuda:0'))
(0, 147, tensor(3.7029, device='cuda:0'))
(0, 148, tensor(3.4835, device='cuda:0'))
(0, 149, tensor(3.6684, device='cuda:0'))
(0, 150, tensor(3.5468, device='cuda:0'))
(0, 151, tensor(3.5562, device='cuda:0'))
(0, 152, tensor(3.8942, device='cuda:0'))
(0, 153, tensor(3.6898, device='cuda:0'))
(0, 154, tensor(3.7238, device='cuda:0'))
(0, 155, tensor(3.6444, device='cuda:0'))
(0, 156, tensor(3.6091, device='cuda:0'))
(0, 157, tensor(3.6397, device='cuda:0'))
(0, 158, tensor(3.5220, device='cuda:0'))
(0, 159, tensor(3.8105, device='cuda:0'))
(0, 160, tensor(3.7223, device='cuda:0'))
(0, 161, tensor(3.6077, device='cuda:0'))
(0, 162, tensor(3.6109, device='cuda:0'))
(0, 163, tensor(3.4783, device='cuda:0'))
(0, 164, tensor(3.4736, device='cuda:0'))
(0, 165, tensor(3.6480, device='cuda:0'))
(0, 166, tensor(3.5062, device='cuda:0'))
(0, 167, tensor(3.6295, device='cuda:0'))
(0, 168, tensor(3.4697, device='cuda:0'))
(0, 169, tensor(3.4080, device='cuda:0'))
(0, 170, tensor(3.4156, device='cuda:0'))
(0, 171, tensor(3.4937, device='cuda:0'))
(0, 172, tensor(3.6491, device='cuda:0'))
(0, 173, tensor(3.6582, device='cuda:0'))
(0, 174, tensor(3.8398, device='cuda:0'))
(0, 175, tensor(3.7783, device='cuda:0'))
(0, 176, tensor(3.6856, device='cuda:0'))
(0, 177, tensor(3.5636, device='cuda:0'))
(0, 178, tensor(3.5413, device='cuda:0'))
(0, 179, tensor(3.5386, device='cuda:0'))
(0, 180, tensor(3.5142, device='cuda:0'))
(0, 181, tensor(3.4066, device='cuda:0'))
(0, 182, tensor(3.3989, device='cuda:0'))
(0, 183, tensor(3.6283, device='cuda:0'))
(0, 184, tensor(3.5219, device='cuda:0'))
(0, 185, tensor(3.3821, device='cuda:0'))
(0, 186, tensor(3.7237, device='cuda:0'))
(0, 187, tensor(3.5439, device='cuda:0'))
(0, 188, tensor(3.5281, device='cuda:0'))
(0, 189, tensor(3.6533, device='cuda:0'))
(0, 190, tensor(3.5908, device='cuda:0'))
(0, 191, tensor(3.8746, device='cuda:0'))
(0, 192, tensor(3.5803, device='cuda:0'))
(0, 193, tensor(3.6152, device='cuda:0'))
(0, 194, tensor(3.6832, device='cuda:0'))
(0, 195, tensor(3.5992, device='cuda:0'))
(0, 196, tensor(3.5664, device='cuda:0'))
(0, 197, tensor(3.5784, device='cuda:0'))
(0, 198, tensor(3.4505, device='cuda:0'))
(0, 199, tensor(3.5612, device='cuda:0'))
(0, 200, tensor(3.4353, device='cuda:0'))
(0, 201, tensor(3.7581, device='cuda:0'))
(0, 202, tensor(3.3343, device='cuda:0'))
Process Process-3:
Traceback (most recent call last):
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/multiprocessing/process.py", line 267, in _bootstrap
    self.run()
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/utils/data/dataloader.py", line 61, in _worker_loop
    data_queue.put((idx, samples))
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/multiprocessing/queues.py", line 390, in put
    return send(obj)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/multiprocessing/queue.py", line 17, in send
    ForkingPickler(buf, pickle.HIGHEST_PROTOCOL).dump(obj)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 224, in dump
    self.save(obj)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 286, in save
    f(self, obj) # Call unbound method with explicit self
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 554, in save_tuple
    save(element)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 286, in save
    f(self, obj) # Call unbound method with explicit self
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 606, in save_list
    self._batch_appends(iter(obj))
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 639, in _batch_appends
    save(x)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 331, in save
    self.save_reduce(obj=obj, *rv)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 401, in save_reduce
    save(args)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 286, in save
    f(self, obj) # Call unbound method with explicit self
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 568, in save_tuple
    save(element)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/pickle.py", line 286, in save
    f(self, obj) # Call unbound method with explicit self
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/multiprocessing/forking.py", line 66, in dispatcher
    rv = reduce(obj)
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/multiprocessing/reductions.py", line 121, in reduce_storage
    fd, size = storage._share_fd_()
RuntimeError: unable to write to file </torch_24339_2222529380> at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/TH/THAllocator.c:383
Traceback (most recent call last):
  File "2_C3D_Model_BC.py", line 118, in <module>
    for vid, labels in mn_dataset_loader:  # This makes many itterations until finishes the whole data set which is really long about 6000 videos this menas the the whole system is really slow and we need to chagne something in the future
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/utils/data/dataloader.py", line 280, in __next__
    idx, batch = self._get_batch()
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/utils/data/dataloader.py", line 259, in _get_batch
    return self.data_queue.get()
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/multiprocessing/queues.py", line 376, in get
    return recv()
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/multiprocessing/queue.py", line 21, in recv
    buf = self.recv_bytes()
  File "/mnt/storage/home/qb18517/qb18517/.conda/envs/pytorch/lib/python2.7/site-packages/torch/utils/data/dataloader.py", line 178, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 24339) exited unexpectedly with exit code 1.
